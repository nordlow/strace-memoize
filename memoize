#!/usr/bin/env python3

# TODO ask on StackExchange if there's a flag to strace to not show failing
# system calls

# TODO Ask Claes Wallin how to fingerprint the Linux kernel version or distribution
# - cat /proc/version
# - cat /proc/mounts

# TODO use gcc -pipe

# TODO add git origin (repo:commit) to input files and sort them on git repo origin
# GIT_REPO:GIT_COMMIT
# TAB rel_path_file_a
# TAB rel_path_file_b
# TAB ...

# TODO parse 'st_mtime using Python's datetime.strptime(some_string, '')

# TODO should we include result of `os.getcwd()` in execve_chash?

# TODO directory chash is chash of list of file names in directory

# TODO use ltrace and reduce env deps by catching all getenv

# TODO add server that does inotify watches for all dirs containing input and
# output files

# TODO Add automatic distribution of execution via chroot. System libs and programs can be hard-linked out read-only from cache

import sys
import os
import subprocess
import os.path
import re
import hashlib
import tempfile
import shutil
import gzip
import pickle                   # cPickle not available in Python3
import json
import getopt

from pprint import pprint as pp # convenient shorthand

# from dbgio import dln

# show results
OPT_VERBOSE = False             # False, True, 'raw'

SYS_CALLS = ['execve', 'open', 'openat', 'stat', 'stat64', 'statfs', 'access']
RAW_CALLS = ['stat']
SYS_CALLS_AT = ['openat']       # Linux

# content hashing algorithm
HASH_NAME = 'sha1'

INDENT_STEP = 2                 # number of spaces per indentation level

include_system_deps = True

SYSTEM_FILE_RE = re.compile(r'/+(usr|lib|lib64|dev|proc|etc|tmp)')

ENCODING = 'utf-8'              # default text encoding

CACHE_DIR = '~/.cache'          # cache directory
MEMOIZE_DIR = os.path.join(os.path.expanduser(CACHE_DIR), 'memoize')
ARTIFACT_DIR = os.path.join(MEMOIZE_DIR, 'artifacts', HASH_NAME.upper())

INPUTS_FILENAME = 'inputs'
OUTPUTS_FILENAME = 'outputs'
INPUTS_FILE_CONTENT_HASH_PREFIX = INPUTS_FILENAME + '_' + HASH_NAME.upper() + '-'

MAX_STRACE_STRING_LENGTH = 4096

SEPARATOR = b'	'               # tab


def dir_is_modified_since(dname, mtime):
    return os.path.getmtime(dname) != mtime # robust to NFS time skews


def file_is_modified_since(fname, mtime, chash):
    if os.path.getmtime(fname) != mtime: # robust to NFS time skews
        return hashlib.new(HASH_NAME, open(fname, 'rb').read) != chash
    else:
        return False


def _is_content_hashable_file(fname):
    """Check if FNAME is a file whose contents can be read and hashed."""
    return not fname.startswith(b'/dev/') and os.path.exists(fname)


def _indent_space(indent):
    return ' '*INDENT_STEP*indent


def _print_syscall_fnames(syscall_s, fnames, indent):
    if not fnames:
        return

    if OPT_VERBOSE == 'raw':
        print(syscall_s + ':')
        for fname in sorted(fnames):
            print(fname)
    else:
        print('syscall=' + syscall_s + '():')

        prev_dname = None

        for fname in filter(lambda fname: (include_system_deps or
                                           not (re.match(pattern=SYSTEM_FILE_RE,
                                                         string=bytes.decode(fname)))),
                            sorted(fnames, reverse=True)):

            dname = os.path.dirname(fname)
            dname_qs = '"' + bytes.decode(dname) + '"'
            bname_qs = '"' + bytes.decode(os.path.basename(fname)) + '"'

            if dname != prev_dname:
                print(_indent_space(indent) + '@ ' + dname_qs + ':')

            indent += 1
            if _is_content_hashable_file(fname):
                mtime = os.path.getmtime(fname)
                if syscall_s in ('stat', 'statfs', 'access') or os.path.isdir(fname):
                    print(_indent_space(indent) + '- ' + bname_qs + ': mtime=' + str(mtime))
                else:
                    chash = hashlib.new(HASH_NAME, open(fname, 'rb').read())
                    chash_s = ' ' + HASH_NAME + "=" + chash.hexdigest()
                    print(_indent_space(indent) + '- ' + bname_qs + ': mtime=' + str(mtime) + chash_s)
            indent -= 1

            prev_dname = dname


def chash_update_tree(chash, curr):
    if (isinstance(curr, bytes)):
        chash.update(curr)
    elif (isinstance(curr, str)):
        chash.update(curr.encode(ENCODING))
    elif (isinstance(curr, list) or
          isinstance(curr, tuple)):
        chash.update(repr(len(curr)).encode(ENCODING))
        for sub in curr:
            chash_update_tree(chash, sub)
    elif (isinstance(curr, dict)):
        chash.update(repr(len(curr)).encode(ENCODING))
        for sub_key, sub_value in curr.items():
            chash_update_tree(chash, sub_key)
            chash_update_tree(chash, sub_value)
    elif (isinstance(curr, float)):
        chash.update(str(curr).encode(ENCODING))
    elif (isinstance(curr, filter)):
        for sub in curr:
            chash_update_tree(chash, sub)
    else:
        raise Exception("Handle curr type")


def execve_chash(execve_call):
    """Create fingerprint (content hash) of call to system function `execve()`
described by parameter EXECVE_CALL."""

    chash = hashlib.new(HASH_NAME)

    execve_fname = execve_call[1]
    chash.update(open(execve_fname, 'rb').read()) # contents of executed binary

    chash.update(os.getcwd().encode(ENCODING))     # current working directory. TODO needed?

    chash_update_tree(chash, execve_call)         # the rest

    return chash


def cache_dir(execve_hexdigest):
    return os.path.join(MEMOIZE_DIR,
                        execve_hexdigest[0:2],
                        execve_hexdigest[2:4],
                        execve_hexdigest[4:])

def cache_makedirs(execve_hexdigest):
    path = cache_dir(execve_hexdigest)
    os.makedirs(name=path, exist_ok=True)
    return path


def store_input_states(rw_list_sorted_by_fname,
                       wr_list,
                       inputs_dir_path):

    inputs_path = os.path.join(inputs_dir_path, INPUTS_FILENAME)
    with open(inputs_path, 'wb') as out_file:
        for input_file, input_status in rw_list_sorted_by_fname:

            if input_file in wr_list:
                continue        # skip output files

            if isinstance(input_status, tuple):
                out_file.write(input_status[1].encode('ascii') +
                               SEPARATOR +
                               str(input_status[0]).encode('ascii') +
                               SEPARATOR +
                               input_file +
                               b'\n')
            else:
                out_file.write(str(input_status).encode('ascii') +
                               SEPARATOR +
                               input_file +
                               b'\n')

def store_output(wr_list, inputs_dir_path):
    """Store output WR_LIST in directory INPUTS_DIR_PATH."""

    wr_list_path = os.path.join(inputs_dir_path, OUTPUTS_FILENAME)
    wr_list_file = open(wr_list_path, 'wb')

    for wr_file in wr_list:

        # create artifact storage directory
        os.makedirs(name=ARTIFACT_DIR, exist_ok=True)

        # copy artifact to compressed storage
        hexdigest = hashlib.new(HASH_NAME,
                                open(wr_file, 'rb').read()).hexdigest()
        artifact_path = os.path.join(ARTIFACT_DIR, hexdigest + '.gz')
        with open(wr_file, 'rb') as src_file:
            with gzip.open(artifact_path, 'wb') as dst_file:
                shutil.copyfileobj(src_file, dst_file)

        # and store hexdigest modification time and path
        wr_list_file.write(hexdigest.encode('ascii') +
                           SEPARATOR +
                           str(os.path.getmtime(wr_file)).encode('ascii') +
                           SEPARATOR +
                           wr_file +
                           b'\n')


def dir_filenames_chash(dname, chash):
    """Hash dir contents of directory name DNAME as list of filenames into CHASH."""
    sub_fnames = os.listdir(dname)

    # hash number of files in dir named dname
    chash.update(str(len(sub_fnames)).encode(ENCODING))

    for sub_fname in sub_fnames:
        # hash dir sub file name
        chash_update_tree(chash, sub_fname)


def try_load_from_cache(cache_dir_path, execve_call, fnames_all):
    cache_dir_inputs = os.listdir(cache_dir_path)
    for rw_file in filter(lambda fname: fname.startswith(INPUTS_FILE_CONTENT_HASH_PREFIX),
                           cache_dir_inputs):
        rw_file_path = os.path.join(cache_dir_path, rw_file, INPUTS_FILENAME)
        pp(rw_file_path)
    return False


def do_it(execve_call, fnames_all):

    execve_hexdigest = execve_chash(execve_call).hexdigest()
    cache_dir_path = cache_makedirs(execve_hexdigest=execve_hexdigest)

    if try_load_from_cache(cache_dir_path=cache_dir_path,
                           execve_call=execve_call,
                           fnames_all=fnames_all):
        return 'cached'

    # fingerprint inputs
    inputs_chash = hashlib.new(HASH_NAME)

    # get inputs and outputs
    rw_list = {}       # read or/and written file names => mtime and optional chash
    wr_list = set()    # written file names
    for (syscall, fnames) in fnames_all.items():
        # pp((syscall, fnames))
        for fname in fnames:

            if re.match(pattern=SYSTEM_FILE_RE,
                        string=bytes.decode(fname)):
                continue        # skip system files for now

            if syscall in ['stat', 'statfs', 'access']:
                if fname not in rw_list:
                    if os.path.isdir(fname):
                        dir_chash = hashlib.new(HASH_NAME)
                        dir_filenames_chash(fname, dir_chash) # TODO needed only for stat?
                        rw_list[fname] = (os.path.getmtime(fname),
                                          dir_chash.hexdigest())
                    else:
                        rw_list[fname] = os.path.getmtime(fname)
            elif syscall in ['open_rdonly',
                             'open_wronly',
                             'open_rdwr']:

                if os.path.isdir(fname):
                    dir_chash = hashlib.new(HASH_NAME)
                    dir_filenames_chash(fname, dir_chash)
                    rw_list[fname] = (os.path.getmtime(fname),
                                      dir_chash.hexdigest())
                else:
                    rw_list[fname] = (os.path.getmtime(fname),
                                      hashlib.new(HASH_NAME, open(fname, 'rb').read()).hexdigest())
                    if syscall in ['open_wronly',
                                   'open_rdwr']:
                        wr_list.add(fname)

    rw_list_sorted_by_fname = sorted(rw_list.items()) # TODO sort by first element only
    for rw_file, rw_status in rw_list_sorted_by_fname:

        if rw_file in wr_list:
            continue            # exclude written files, because they are saved

        if os.path.isdir(rw_file):
            dir_filenames_chash(dname=rw_file,
                                chash=inputs_chash)
        else:
            chash_update_tree(inputs_chash, rw_status[1]) # only content hash here

    inputs_dir_path = os.path.join(cache_dir_path,
                                   INPUTS_FILE_CONTENT_HASH_PREFIX +
                                   inputs_chash.hexdigest())

    # create input root directory
    os.makedirs(name=inputs_dir_path,  exist_ok=True)

    # write execve call
    open(os.path.join(cache_dir_path,
                      'execve_call.python-repr'),
         'w').write(repr(execve_call))

    store_input_states(rw_list_sorted_by_fname=rw_list_sorted_by_fname,
                       wr_list=wr_list,
                       inputs_dir_path=inputs_dir_path)

    store_output(wr_list=wr_list,
                 inputs_dir_path=inputs_dir_path)

    return 'uncached'


def process_strace_output_file(out_file):

    first_execve_call = None
    trace = []                  # trace tree

    # hash from system call name to call instances set
    fnames_all = {}
    fnames_all['open_rdonly'] = set()
    fnames_all['open_wronly'] = set()
    fnames_all['open_rdwr']   = set()
    fnames_all['stat']        = set()
    fnames_all['statfs']      = set()
    fnames_all['openat']      = set()
    fnames_all['access']      = set()

    out_file.seek(0)              # reset it
    for out_line in out_file:
        if b'ENOENT' not in out_line: # skip failing calls
            # print(out_line)

            pid_, out_rest = out_line.split(None, 1)

            pid = int(pid_) # decode PID integer
            # print(pid)

            try:
                syscall, out_rest = out_rest.split(b'(', 1)
                syscall_s = bytes.decode(syscall)
                # print(syscall_s)

                fname, out_rest = out_rest.split(b', ', 1)
                fname = os.path.normpath(fname[1:-1])

                if (fname.startswith(b'//usr') or
                    fname.startswith(b'//lib')):
                    fname = fname[1:] # skip first slash

                # in decreasing probability
                if syscall == b'execve':
                    # get args
                    _args, out_rest = out_rest.split(b'], [', 1)
                    argv = eval(_args[1:]) # tuple of strings

                    # get environment
                    _env, out_rest = out_rest.split(b']) = ', 1)
                    env = eval(_env) # tuple of strings containing ENV_VAR=VALE

                    # store and fingerprint
                    execve_call = (syscall, fname, argv, env)
                    if first_execve_call is None:
                        first_execve_call = execve_call
                        trace.append(execve_call)

                elif syscall == b'stat':
                    fnames_all['stat'].add(fname)
                elif syscall == b'statfs':
                    fnames_all['statfs'].add(fname)
                elif syscall == b'openat':
                    fnames_all['openat'].add(fname)
                    # print(fname, out_rest)
                elif syscall == b'open':
                    if out_rest.startswith(b'O_RDONLY'): # read-only
                        fnames_all['open_rdonly'].add(fname)
                    elif out_rest.startswith(b'O_WRONLY'):
                        # write-only create into new file
                        fnames_all['open_wronly'].add(fname)
                    elif out_rest.startswith(b'O_RDWR|O_CREAT|O_TRUNC'): # write-only
                        fnames_all['open_wronly'].add(fname)
                    elif out_rest.startswith(b'O_RDWR|O_CREAT'): # read-write
                        fnames_all['open_rdwr'].add(fname)
                    else:
                        raise Exception('unknown out_rest' + str(out_rest))
                elif syscall == b'access':
                    fnames_all['access'].add(fname)
                else:
                    print('Handle system call ' + syscall_s)

            except ValueError:
                pass

    return (first_execve_call, trace, fnames_all)


def memoized_run(args, trace_childs=True):

    indent = 0

    with tempfile.NamedTemporaryFile() as out_file:

        # collect flags
        strace_std_flags = ['-v',
                            '-s' + str(MAX_STRACE_STRING_LENGTH)]
        if trace_childs:
            strace_std_flags.append('-f')
        outfile_flags = ['-o', out_file.name]
        sys_calls_flags = ['-e', 'trace=' +
                           ','.join(SYS_CALLS + SYS_CALLS_AT)]
        strace_cmd = ['strace'] + strace_std_flags + outfile_flags + sys_calls_flags + args

        ret = subprocess.run(args=strace_cmd, shell=False)

        (first_execve_call, trace, fnames_all) = process_strace_output_file(out_file=out_file)

        do_it(execve_call=first_execve_call,
              fnames_all=fnames_all)

        if OPT_VERBOSE:

            print("\n============================= TRACE RESULTS ===================================\n")

            if OPT_VERBOSE:
                indent += 1
                _print_syscall_fnames(syscall_s='stat', fnames=fnames_all['stat'], indent=indent)
                _print_syscall_fnames(syscall_s='statfs', fnames=fnames_all['statfs'], indent=indent)
                _print_syscall_fnames(syscall_s='access', fnames=fnames_all['access'], indent=indent)
                _print_syscall_fnames(syscall_s='open-rdonly', fnames=fnames_all['open_rdonly'], indent=indent)
                _print_syscall_fnames(syscall_s='open-wronly', fnames=fnames_all['open_wronly'], indent=indent)
                _print_syscall_fnames(syscall_s='open-rdwr', fnames=fnames_all['open_rdwr'], indent=indent)
                _print_syscall_fnames(syscall_s='openat', fnames=fnames_all['openat'], indent=indent)

        return (ret, trace)


if __name__ == '__main__':

    opts, args = getopt.getopt(sys.argv[1:], 'dv:')

    for opt, value in opts:
        if opt == '-v':
            OPT_VERBOSE = True

    completedProcess, trace = memoized_run(args)
    # pp(trace)
    sys.exit(completedProcess.returncode)
